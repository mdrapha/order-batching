{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# Configuração inicial do PySpark\n",
    "conf = SparkConf()\n",
    "conf.setAppName(\"MeuAplicativoPySpark\")\n",
    "conf.setMaster(\"local[*]\")  # Usar todos os núcleos locais para execução\n",
    "\n",
    "# Criação da SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession Criada!\n",
      "+-------+--------+-----+-------------+-----+\n",
      "|ONDA_ID|CAIXA_ID|PECAS|  CLASSE_ONDA|  SKU|\n",
      "+-------+--------+-----+-------------+-----+\n",
      "|      4|      12|    1|CLASSE_ONDA_1|SKU_1|\n",
      "+-------+--------+-----+-------------+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "+-----+--------+---------+-----+\n",
      "|ANDAR|CORREDOR|      SKU|PECAS|\n",
      "+-----+--------+---------+-----+\n",
      "|    0|       2|SKU_17028|  193|\n",
      "+-----+--------+---------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar se a sessão Spark está funcionando\n",
    "print(\"SparkSession Criada!\")\n",
    "spark.sparkContext.setLogLevel(\"WARN\")  # Define o nível de log para evitar muitas mensagens de depuração\n",
    "\n",
    "# Leitura de dois arquivos CSV e salvando em variáveis\n",
    "caixas_df = spark.read.csv(\"../data/caixas.csv\", header=True, inferSchema=True)\n",
    "estoque_df = spark.read.csv(\"../data/estoque.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Mostrando o conteúdo dos DataFrames\n",
    "caixas_df.show(1)\n",
    "estoque_df.show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma visão temporária para utilizar SQL puro\n",
    "caixas_df.createOrReplaceTempView(\"caixas\")\n",
    "estoque_df.createOrReplaceTempView(\"estoque\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-----+------+-----------------------+-----------------------+----+\n",
      "|  CLASSE_ONDA|CAIXA_ID|ANDAR|   SKU|TOTAL_PECAS_NECESSARIAS|TOTAL_PECAS_DISPONIVEIS|DIFF|\n",
      "+-------------+--------+-----+------+-----------------------+-----------------------+----+\n",
      "|CLASSE_ONDA_1|      12|    0| SKU_2|                      1|                     84|  83|\n",
      "|CLASSE_ONDA_1|      12|    0| SKU_3|                      1|                    852| 851|\n",
      "|CLASSE_ONDA_1|      12|    0| SKU_4|                      1|                    670| 669|\n",
      "|CLASSE_ONDA_1|      12|    0| SKU_6|                      4|                    233| 229|\n",
      "|CLASSE_ONDA_1|      12|    0| SKU_9|                      4|                    152| 148|\n",
      "|CLASSE_ONDA_1|      12|    0|SKU_11|                      1|                      1|   0|\n",
      "|CLASSE_ONDA_1|      12|    0|SKU_12|                      2|                    132| 130|\n",
      "|CLASSE_ONDA_1|      12|    0|SKU_14|                      8|                    271| 263|\n",
      "|CLASSE_ONDA_1|      12|    0|SKU_15|                      8|                    117| 109|\n",
      "|CLASSE_ONDA_1|      12|    0|SKU_17|                      1|                     64|  63|\n",
      "|CLASSE_ONDA_1|      12|    1| SKU_1|                      1|                      6|   5|\n",
      "|CLASSE_ONDA_1|      12|    1| SKU_5|                      1|                   2667|2666|\n",
      "|CLASSE_ONDA_1|      12|    1|SKU_11|                      1|                    174| 173|\n",
      "|CLASSE_ONDA_1|      12|    2| SKU_1|                      1|                    886| 885|\n",
      "|CLASSE_ONDA_1|      12|    2| SKU_3|                      1|                   1220|1219|\n",
      "|CLASSE_ONDA_1|      12|    2| SKU_7|                      9|                    360| 351|\n",
      "|CLASSE_ONDA_1|      12|    2| SKU_8|                     10|                    435| 425|\n",
      "|CLASSE_ONDA_1|      12|    2| SKU_9|                      4|                    257| 253|\n",
      "|CLASSE_ONDA_1|      12|    2|SKU_10|                      2|                    290| 288|\n",
      "|CLASSE_ONDA_1|      12|    2|SKU_13|                      9|                    203| 194|\n",
      "+-------------+--------+-----+------+-----------------------+-----------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Agregando as quantidades de cada SKU por classe de onda e caixa\n",
    "agregado_caixa = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        CLASSE_ONDA,\n",
    "        CAIXA_ID,\n",
    "        SKU,\n",
    "        PECAS\n",
    "    FROM caixas\n",
    "\n",
    "\"\"\")\n",
    "agregado_caixa.createOrReplaceTempView(\"agregado_caixa\")\n",
    "\n",
    "# Agregando as quantidades de cada SKU por andar\n",
    "agregado_estoque = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        ANDAR,\n",
    "        SKU,\n",
    "        SUM(PECAS) AS TOTAL_PECAS_DISPONIVEIS\n",
    "    FROM estoque\n",
    "    GROUP BY\n",
    "        ANDAR, SKU\n",
    "\"\"\")\n",
    "agregado_estoque.createOrReplaceTempView(\"agregado_estoque\")\n",
    "\n",
    "# Verificando quantas peças são necessárias em cada caixa e quantas temos no andar\n",
    "dados_necessarios_disponiveis = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        ac.CLASSE_ONDA,\n",
    "        ac.CAIXA_ID,\n",
    "        ae.ANDAR,\n",
    "        ac.SKU,\n",
    "        ac.PECAS AS TOTAL_PECAS_NECESSARIAS,\n",
    "        ae.TOTAL_PECAS_DISPONIVEIS,\n",
    "        (ae.TOTAL_PECAS_DISPONIVEIS - ac.PECAS) AS DIFF\n",
    "        \n",
    "    FROM agregado_caixa ac\n",
    "    LEFT JOIN agregado_estoque ae\n",
    "    ON ac.SKU = ae.SKU\n",
    "    ORDER BY\n",
    "        ac.CLASSE_ONDA, ac.CAIXA_ID, ae.ANDAR\n",
    "\"\"\")\n",
    "dados_necessarios_disponiveis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23299"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrando os casos onde o DIFF > 0\n",
    "caixas_easy = dados_necessarios_disponiveis.filter(\"DIFF >= 0\")\n",
    "caixas_easy.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caixas_hard = dados_necessarios_disponiveis.filter(\"DIFF < 0\")\n",
    "caixas_hard.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
